{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e2f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import TimeDistributed, Dense, Input, GlobalAveragePooling2D ,BatchNormalization ,Flatten ,Bidirectional , GRU , Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370bd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a sequence of 15 image frames from a sample folder\n",
    "def load_sequence_frames(sample_path, seq_len=15, step = 2, size=(224, 224)):\n",
    "    frames = []\n",
    "    image_files = sorted(sample_path.glob('*.png'))\n",
    "\n",
    "    # Take 15 frames with a stride of 2 (i.e., pick every 2nd frame)\n",
    "    selected_files = image_files[::step][:seq_len]\n",
    "\n",
    "    for img_path in selected_files:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, size)\n",
    "        frames.append(img)\n",
    "\n",
    "    frames = np.array(frames, dtype=np.float32) / 255.0\n",
    "    return frames  # Shape: (15, 224, 224, 3)\n",
    "\n",
    "# Dataset generator\n",
    "def data_generator(root_dir):\n",
    "    root = Path(root_dir)\n",
    "    classes = sorted([d.name for d in root.iterdir() if d.is_dir()])\n",
    "    print(classes)\n",
    "    class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "\n",
    "    samples, labels = [], []\n",
    "    for c in classes:\n",
    "        for sample_folder in (root / c).iterdir():\n",
    "            if sample_folder.is_dir():\n",
    "                samples.append(sample_folder)\n",
    "                labels.append(class_to_idx[c])\n",
    "\n",
    "    def gen():\n",
    "        for sample_path, label in zip(samples, labels):\n",
    "            seq = load_sequence_frames(sample_path)\n",
    "            yield seq, label\n",
    "\n",
    "    return tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(15, 224, 224, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2223d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No augmentation applied here\n",
    "train_dataset = data_generator(f\"{DATA_DIR}/train\")\\\n",
    "    .shuffle(100)\\\n",
    "    .batch(4)\\\n",
    "    .repeat()\\\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = data_generator(f\"{DATA_DIR}/val\")\\\n",
    "    .batch(4)\\\n",
    "    .prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0dd740",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "sequence_length = 15\n",
    "image_size = (224, 224, 3)\n",
    "\n",
    "# Input: sequence of images\n",
    "inputs = Input(shape=(sequence_length, *image_size))\n",
    "\n",
    "# Use MobileNet as CNN feature extractor (weights pretrained on ImageNet)\n",
    "cnn_base = MobileNetV2(include_top=False, weights='imagenet', input_shape=image_size)\n",
    "\n",
    "# unFreeze CNN base initially\n",
    "cnn_base.trainable = True\n",
    "\n",
    "# Apply CNN to each frame separately via TimeDistributed\n",
    "x = TimeDistributed(cnn_base)(inputs)\n",
    "x = TimeDistributed(BatchNormalization())(x)\n",
    "x = TimeDistributed(GlobalAveragePooling2D())(x)\n",
    "\n",
    "# Apply a GRU layer with 128 units to capture temporal dependencies across frames,\n",
    "# with L2 regularization (weight decay) to reduce overfitting\n",
    "x = x = Bidirectional(GRU(128))(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
